import os
import glob

# --- ã€æ–°å¢ã€‘è®¾ç½® Hugging Face é•œåƒåœ°å€ï¼Œè§£å†³è¿æ¥è¶…æ—¶é—®é¢˜ ---
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import MarkdownHeaderTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma

# --- é…ç½®è·¯å¾„ ---
SOP_DIR = "./data/sops"
PERSIST_DIRECTORY = "./chroma_db"

def load_and_split_sops():
    # ... (è¿™éƒ¨åˆ†ä»£ç ä¸ç”¨å˜) ...
    print(f"ğŸ“‚ å¼€å§‹æ‰«æç›®å½•: {SOP_DIR}")
    files = glob.glob(os.path.join(SOP_DIR, "*.md"))
    
    if not files:
        print("âŒ é”™è¯¯: data/sops/ ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ° .md æ–‡ä»¶ï¼")
        return []

    all_splits = []
    
    headers_to_split_on = [
        ("#", "Header 1"),
        ("##", "Header 2"),
        ("###", "Header 3"),
    ]
    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)

    for file_path in files:
        print(f"   - å¤„ç†æ–‡æ¡£: {os.path.basename(file_path)}")
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
                splits = markdown_splitter.split_text(text)
                for split in splits:
                    split.metadata["source"] = os.path.basename(file_path)
                all_splits.extend(splits)
                print(f"     -> åˆ‡åˆ†ä¸º {len(splits)} ä¸ªè¯­ä¹‰å—")
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

    return all_splits

def build_vector_store(splits):
    print("\nğŸ§  æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹ (BAAI/bge-m3)... (ç¬¬ä¸€æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼Œçº¦éœ€å‡ åˆ†é’Ÿ)")
    
    # ã€æ³¨æ„ã€‘è¿™é‡Œä¼šè‡ªåŠ¨ä½¿ç”¨ä¸Šé¢è®¾ç½®çš„ hf-mirror.com é•œåƒ
    try:
        embedding_model = HuggingFaceEmbeddings(
            model_name="BAAI/bge-m3",
            # å¦‚æœæ˜¾å­˜ä¸å¤Ÿï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Šï¼Œå¼ºåˆ¶ç”¨CPUè·‘embedding
            # model_kwargs={'device': 'cpu'} 
        )
    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®: {e}")
        return None

    print(f"ğŸ’¾ æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•ï¼Œå…± {len(splits)} æ¡æ•°æ®...")
    
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embedding_model,
        persist_directory=PERSIST_DIRECTORY
    )
    print(f"âœ… å‘é‡åº“å·²ä¿å­˜è‡³: {PERSIST_DIRECTORY}")
    return vectorstore

def test_query(vectorstore):
    if not vectorstore:
        return
    print("\nğŸ” --- å¼€å§‹æ£€ç´¢æµ‹è¯• ---")
    
    # æµ‹è¯•æ¡ˆä¾‹ 1: å†…éƒ¨æµ‹è¯•åŠ ç™½
    query1 = "æˆ‘æ˜¯æµ‹è¯•ï¼Œæƒ³ç”³è¯·ä¸ªåŠ ç™½è´¦å·è·‘æµç¨‹"
    print(f"\nâ“ é—®é¢˜: {query1}")
    results = vectorstore.similarity_search(query1, k=2)
    for i, res in enumerate(results):
        print(f"   [ç»“æœ{i+1}] (æ¥æº: {res.metadata['source']})\n   {res.page_content[:100].replace(chr(10), ' ')}...") # æŠŠæ¢è¡Œç¬¦æ›¿æ¢ä¸ºç©ºæ ¼æ˜¾ç¤º

    # æµ‹è¯•æ¡ˆä¾‹ 2: ç”¨æˆ·è¢«æ‹¦æˆª
    query2 = "æ”¯ä»˜æç¤ºé£é™©æ‹¦æˆªæ€ä¹ˆåŠï¼Ÿ"
    print(f"\nâ“ é—®é¢˜: {query2}")
    results = vectorstore.similarity_search(query2, k=2)
    for i, res in enumerate(results):
        print(f"   [ç»“æœ{i+1}] (æ¥æº: {res.metadata['source']})\n   {res.page_content[:100].replace(chr(10), ' ')}...")

if __name__ == "__main__":
    splits = load_and_split_sops()
    if splits:
        vector_db = build_vector_store(splits)
        test_query(vector_db)